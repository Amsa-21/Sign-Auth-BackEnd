{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from cryptography.hazmat.primitives import hashes\n",
    "from cryptography.hazmat.primitives.asymmetric import padding\n",
    "from cryptography.hazmat.primitives import serialization\n",
    "from cryptography.hazmat.backends import default_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signature verified for timestamp: 2024-07-23T10:15:04.038610\n"
     ]
    }
   ],
   "source": [
    "data = \"Message to be timestamped\"\n",
    "\n",
    "response = requests.post('http://localhost:8090/timestamp', json={'data': data})\n",
    "if response.status_code == 200:\n",
    "  response_data = response.json()\n",
    "  timestamp = response_data['timestamp']\n",
    "  signature = bytes.fromhex(response_data['signature'])\n",
    "  public_key_pem = response_data['public_key']\n",
    "\n",
    "  public_key = serialization.load_pem_public_key(\n",
    "    public_key_pem.encode(),\n",
    "    backend=default_backend()\n",
    "  )\n",
    "\n",
    "  data_hash = hashes.Hash(hashes.SHA256(), backend=default_backend())\n",
    "  data_hash.update(data.encode())\n",
    "  digest = data_hash.finalize()\n",
    "\n",
    "  try:\n",
    "    public_key.verify(\n",
    "      signature,\n",
    "      digest,\n",
    "      padding.PSS(\n",
    "        mgf=padding.MGF1(hashes.SHA256()),\n",
    "        salt_length=padding.PSS.MAX_LENGTH\n",
    "      ),\n",
    "      hashes.SHA256()\n",
    "    )\n",
    "    print(f\"Signature verified for timestamp: {timestamp}\")\n",
    "  except Exception as e:\n",
    "    print(f\"Verification failed: {e}\")\n",
    "else:\n",
    "  print(\"Failed to get timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\"U\\xee\\xd3U\\xd8T-\\x0c\\x93u\\xd7B\\xff\\xc8\\xd5!\\xc8K\\xb8;\\x86\\xe7\\xdd\\x87\\xa1\\xa5\\xd3\\x8cs\\x9eC\\x19\\x01\\x1b\\xcdQ\\x97\\x8a\\xf7<\\xcaTc\\xa9B\\xf1\\x8d\\x98^\\x0bc\\xae\\xfb\\x90\\xedQ\\xb2\\x92\\xf4\\xea\\xfa\\xfbz\\xf1=q}\\xeb\\x86\\x0f\\xd2\\xd5\\xe0\\xad6Rt\\'3\\xbe\\x1d1*\\x10\\xbdU\\xbe\\xc0\\x80\\x90\\xae\\xb5\\x8et\\xfe\\x9cX^&\\xdczQp\\'Lg\\xd54D\\x05Nm\\xb9\\xc1\\xbc\\x05\\x1a\\xce\\xd4r\\x13}\\x138v\\x19\\x9d0\\xce\\x91\\xeb\\x85\\xa9\\x1f\\x1d\\xdc\\xf0*\\xea=\\x07n\\xcb\\x07\\x8d\\xc5\\xd8\\xd7U\\xc1A\\x15GYc\\xb6|mq\\x01\\x15\\x0b\\x99\\xe7\\xd0\\xac\\x0c\\xcb\\xe7\\xe10l\\xec\\x89@I\\xb2\\n\\xf6\\xd3tH\\xb5\\x82*D\\xb5h\\xfe\\x05\\xcd\\xf6\\xf4X\\xd9\\xa0\\x82\\xdf\\x1a\\xb9\\xd7\\xef\\xb3\\x03\\xd0\\\\\\x8a\\x14\\xdd\\x98\\x10\\xcc \\xf5\\xc9\\xde\\x18W\\x90\\xa4 \\xff\\x9e\\xd1)\\xcf\\xe1\\xaa3\\x88Z\\xcc\\xe1\\xc3\\xac\\xd8<MC\\x86\\xb8\\xc7\\x00{\\xcc\\xc2\\x15\\x83\\xd5\\xaa$\\x06\\xa8u\\x17'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-----BEGIN PUBLIC KEY-----\\nMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAqWGPKO6eEo8hEyHGyhop\\nrND4wIsJK/HYR/kE+9sT04NrWOHs21YWKATYu0ze/8JTSucTdhw7lu3uBAeiFCxa\\nC6vpy+Lx9lQ/hSwcTcNWsdr/SjtjjoLqGTE5QNZrN1JtHTwevyD6HM4FbJMco2Wy\\nR34eIR/A66rCzftQX/8FIMjpapfyuJ6CKfn040e6dbJfUC5IZHNVGORwzSsQ3xwf\\nDc8/GXt9ETp3IZALvbcn/Xn+dinEvBMT9fGZU+Q4VMuDDZzqmi8bgvf6qZQkN1Eo\\nO2hnvRMKdeoGCVCUxd/EIv02ZDHvLoMKOySHWbHB3VGVvXJyd6QPizAOdftn0vQA\\nfQIDAQAB\\n-----END PUBLIC KEY-----\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public_key_pem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras_facenet import FaceNet\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import base64, cv2\n",
    "\n",
    "model = SVC(kernel='linear', probability=True)\n",
    "encoder = LabelEncoder()\n",
    "embedder = FaceNet()\n",
    "\n",
    "class FACELOADING:\n",
    "  def __init__(self, data):\n",
    "    self.data = data\n",
    "    self.X = []\n",
    "    self.Y = []\n",
    "\n",
    "  def base64ToImg(self, base64_string):\n",
    "    image_data = base64.b64decode(base64_string)\n",
    "    np_arr = np.frombuffer(image_data, np.uint8)\n",
    "    return cv2.cvtColor(cv2.imdecode(np_arr, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB) \n",
    "\n",
    "  def load_classes(self):\n",
    "    for element in self.data:\n",
    "      self.X.append(self.base64ToImg(element[\"picture\"]))\n",
    "      self.Y.append(element[\"person\"])\n",
    "    return np.asarray(self.X), np.asarray(self.Y)\n",
    "\n",
    "def get_trainset(conn):\n",
    "  cursor = conn.cursor()\n",
    "  query = 'SELECT * FROM trainset;'\n",
    "  cursor.execute(query)\n",
    "  rows = cursor.fetchall()\n",
    "  cursor.close()\n",
    "  conn.close()\n",
    "  data = []\n",
    "  for row in rows:\n",
    "    data.append({\n",
    "      \"id\": row[0],\n",
    "      \"person\": row[1],\n",
    "      \"picture\": row[2],\n",
    "    })\n",
    "  return data\n",
    "\n",
    "def get_embedding(face_img):\n",
    "  face_img = face_img.astype('float32') # 3D(160x160x3)\n",
    "  face_img = np.expand_dims(face_img, axis=0)\n",
    "  # 4D (Nonex160x160x3)\n",
    "  yhat= embedder.embeddings(face_img)\n",
    "  return yhat[0] # 512D image (1x1x512)\n",
    "\n",
    "def get_trained_model(data):\n",
    "  try:\n",
    "    faceloading = FACELOADING(data)\n",
    "    X, Y = faceloading.load_classes()\n",
    "\n",
    "    EMBEDDED_X = []\n",
    "    for img in X:\n",
    "      EMBEDDED_X.append(get_embedding(img))\n",
    "    EMBEDDED_X = np.asarray(EMBEDDED_X)\n",
    "    encoder.fit(Y)\n",
    "    Y_ENCODDED = encoder.transform(Y)\n",
    "    model.fit(EMBEDDED_X, Y_ENCODDED)\n",
    "    return model, encoder\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "    return None, None\n",
    "\n",
    "def predict_face(face, model, encoder):\n",
    "  if not face.all() == None:\n",
    "    face_embed = get_embedding(face)\n",
    "    test_im = [face_embed]\n",
    "    ypreds = model.predict(test_im)\n",
    "    prob = model.predict_proba(test_im)[0][0]\n",
    "    return encoder.inverse_transform(ypreds)[0], prob\n",
    "  return \"No face detected !\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "def get_db_connection():\n",
    "  conn = psycopg2.connect('postgres://avnadmin:AVNS_jJdwHlhkwoHcODhE83V@pg-367c7a2d-amsata2009-bad2.f.aivencloud.com:18480/defaultdb?sslmode=require')\n",
    "  return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n"
     ]
    }
   ],
   "source": [
    "data = get_trainset(get_db_connection())\n",
    "model, encoder = get_trained_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtcnn.mtcnn import MTCNN\n",
    "\n",
    "detector = MTCNN()\n",
    "\n",
    "def base64ToImg(base64_string):\n",
    "  try:\n",
    "    image_data = base64.b64decode(base64_string)\n",
    "    np_arr = np.frombuffer(image_data, np.uint8)\n",
    "    return cv2.cvtColor(cv2.imdecode(np_arr, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB) \n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "def image_to_base64(image_np):\n",
    "  _, buffer = cv2.imencode('.jpg', image_np)\n",
    "  base64_image = base64.b64encode(buffer).decode('utf-8')\n",
    "  return base64_image\n",
    "\n",
    "def faceDetector(frame):\n",
    "  faces = detector.detect_faces(frame)\n",
    "  if faces:\n",
    "    x, y, w, h = faces[0]['box']\n",
    "    frame = frame[y:y+h, x:x+w]\n",
    "    frame = cv2.resize(frame, (160, 160))\n",
    "    return frame\n",
    "  return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n"
     ]
    }
   ],
   "source": [
    "face = base64ToImg(data[5][\"picture\"])\n",
    "faceD = faceDetector(face)\n",
    "if faceD is not None:\n",
    "  res, prob = predict_face(faceD, model, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Amsata DIAGNE 776689197', 0.9577604141218852)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
